#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Date: Created on 26 Oct 2023 13:37
# @Author: Yao LI
# @File: spagrn/receptor_simulation.py

import os
import pandas as pd
import scanpy as sc
from pyarrow import feather
import pyarrow


class Simulator(object):
    """
    Down-stream
    handle scMultiSim outputs
    """
    def __init__(self):
        self.data = None
        self.tfs = None
        self.tf_names = None
        self.motif_names = None
        self.receptors = None
        self.ligands = None
        self.targets = None
        self.total_genes = None

        self.lr_gt = None
        self.grn_gt = None

        self.counts = None
        self.noise_ids = None  # noise genes
        self.real_ids = None  # real genes

    def get_lr(self, df):
        """
        Load Ligand-Receptor ground truth if available
        :param df:
        :return:
        """
        self.lr_gt = df
        self.receptors = list(set(df.receptor))
        self.ligands = list(set(df.ligand))

    def get_tg(self, df):
        """
        Load TF-Target ground truth (must have)
        :param df:
        :return:
        """
        self.grn_gt = df
        self.targets = list(set(df['regulated.gene']))
        self.tfs = list(set(df['regulator.gene']))

    def recognize_ids(self):
        """
        for counts gene index
        :return:
        """
        if self.counts:
            self.total_genes = list(self.counts.index)
            self.noise_ids = [i for i in self.total_genes if 'gene' in i]
            self.real_ids = [i for i in self.total_genes if 'gene' not in i]
        else:
            raise ValueError("Expression matrix is not available, load expression matrix first")

    def load_exp(self, counts):
        """
        when loading only one csv file created by scMultiSim
        :param counts:
        :return:
        """
        self.counts = counts
        self.recognize_ids()

    def load_multi_samples(self):
        """
        when loading multiple csv files generated by scMultiSim
        :return:
        """
        # Load in needed data
        df_list = []
        n = 0
        for num, tf in enumerate(self.tfs[:5]):
            df2 = pd.read_csv(f'counts_{tf}_{num}.csv', index_col=0)
            new_cell_num = df2.shape[1]
            new_cell_names = [f'cell{x}' for x in list(range(n + 1, n + new_cell_num + 1))]
            df2.columns = new_cell_names
            n = n + new_cell_num
            df_list.append(df2)
        # merge into one dataframe
        df = pd.concat(df_list, axis=1).fillna(0).astype(int)
        df3 = pd.read_csv('counts_addition.csv', index_col=0)
        gene_index = [i if 'gene' not in i else f'{i}3' for i in list(df3.index)]
        df3.index = gene_index
        df = pd.concat([df, df3]).fillna(0).astype(int)
        self.noise_ids = [i for i in list(df.index) if 'gene' in i]

    def target_names(self, names: pd.DataFrame):
        """
        assign real gene names to TF target genes only
        :param names:
        :return:
        """
        pass

    def load_multiple_gts(self):
        """
        multiple GRN gts
        :return:
        """
        pass


def get_dir(gt: pd.DataFrame, regulators, regulator_key='regulator.gene', value_key='regulator.effect', regulated_key='regulated.gene'):
    """

    :param gt:
    :param regulators: regulator: TF or ligand
    :param regulator_key:
    :param value_key:
    :param regulated_key:
    :return:
    """
    dir = {}
    for reg in regulators:
        sub = gt[gt[regulator_key] == reg]
        sorted_sub = sub.sort_values(by=value_key, ascending=False)
        dir[reg] = list(sorted_sub[regulated_key])
    return dir


if __name__ == '__main__':
    # 1. LOAD SIMULATED DATA
    fn_base = '/dellfsqd2/ST_OCEAN/USER/liyao1/07.spatialGRN/exp/07.simulation/ver9'
    coor = pd.read_csv(os.path.join(fn_base, 'coord_5types.csv'), index_col=0)
    counts = pd.read_csv(os.path.join(fn_base, 'counts_5types_100genes.csv'), index_col=0)
    celltypes = pd.read_csv(os.path.join(fn_base, 'celltype_5types.csv'), index_col=0)
    grn_gt = pd.read_csv(os.path.join(fn_base, 'GRN_parameter.csv'))
    grn_gt = grn_gt[grn_gt['regulator.gene'] != 10]
    lr_gt = pd.read_csv(os.path.join(fn_base, 'LR_parameter_100.csv'))

    noise_ids = [i for i in counts.index if 'gene' in i]
    tfs = list(set(grn_gt['regulator.gene']))  # 5 tfs

    simulator = Simulator()
    simulator.load_exp(counts)
    simulator.get_lr(lr_gt)
    simulator.get_tg(grn_gt)

    # 2. REAL GENE NAMES
    # 2.1 ranking database
    fn = '/dellfsqd2/ST_OCEAN/USER/liyao1/06.stereopy/database/dm6_v10_clust.genes_vs_motifs.rankings.feather'
    rdb = pyarrow.feather.read_feather(fn)
    # 2.2 TF real names
    tf_names = ['Adf1', 'Aef1', 'grh', 'kn', 'tll']
    motif_names = ['bergman__Adf1', 'bergman__Aef1', 'bergman__grh', 'metacluster_172.20', 'metacluster_140.5']
    # create divided ... prepare for the next step
    tf_motif_dir = dict(zip(tf_names, motif_names))
    tf_id_dir = dict(zip(tfs, tf_names))
    total_id = []
    total_id += tfs
    total_name = []
    total_name += tf_names


    def assign_gene_names(tfs:list, rdb:pd.DataFrame, grn_gt:pd.DataFrame, lr_gt:pd.DataFrame, total_name:list, total_id:list, noise_ids:list):
        """

        :param tfs:
        :param rdb:
        :param grn_dir:
        :param total_name:
        :param total_id:
        :param noise_ids:
        :return:
        """
        grn_dir = get_dir(grn_gt, tfs)
        # lr_dir = get_dir(lr_gt, list(set(lr_gt.ligand)), regulator_key='ligand', value_key='effect', regulated_key='receptor')
        # 1. for targets:
        # tf targets names, assign real names to tf targets. choose top n genes for each motif(TF).
        for tf in tfs:
            current_len = len(total_name)  # find current total_name number
            one_motif = tf_motif_dir[tf_id_dir[tf]]  # for each motif, find its gene rankings
            # find top genes for the motif
            sub = rdb[rdb.motifs == one_motif].drop('motifs', axis=1)  # remove motif column, only sort gene columns
            sorted_sub = sub.sort_values(by=(sub.index.values[0]), axis=1)  # sort columns (genes) by rank numbers
            top_num = len(grn_dir[tf])
            total_id += grn_dir[tf]
            # match real gene name with gene id
            for tg in sorted_sub.columns:
                if tg not in total_name:
                    total_name.append(tg)
                if len(total_name) == (current_len + top_num):
                    break

        # at this point, total names are unique, total ids have duplicates
        # remove duplicates
        name_df1 = pd.DataFrame({'id': total_id, 'name': list(total_name)}).drop_duplicates(subset='id', keep='first').astype(str)
        total_name = list(name_df1.name)
        total_id = list(name_df1.id)
        # at this point, len(set(total_name)) should equal to len(set(total_id))

        # PART TWO
        # some of the gene names are used. find out the rest unused gene names,
        # to avoid assign used gene name to noise genes and ligand and receptors
        total_rdb_names = set(rdb.columns) - set('motifs')
        rest_rdb_names = list(total_rdb_names - set(total_name))
        # 2. for noise genes
        from random import sample
        noise_genes_names = sample(rest_rdb_names, k=len(noise_ids))
        # !! random.choices returns duplicated items, use random.sample instead
        # add noise names into total_name
        total_name += noise_genes_names
        total_id += noise_ids
        # 3. for ligands
        rest_rdb_names = list(set(rest_rdb_names) - set(total_name))
        ligand_ids = list(set(lr_gt.ligand))
        ligand_genes_names = sample(rest_rdb_names, k=len(ligand_ids))
        total_name += ligand_genes_names
        total_id += ligand_ids
        # 4. for receptor genes that are not TF targets
        rest_rdb_names = list(set(rest_rdb_names) - set(total_name))
        receptors_not_targets_ids = set(lr_gt.receptor)-set(grn_gt['regulated.gene'])
        receptors_not_targets_names = sample(rest_rdb_names, k=len(receptors_not_targets_ids))
        total_name += receptors_not_targets_names
        total_id += receptors_not_targets_ids

        # create names df
        name_df = pd.DataFrame({'id': total_id, 'name': list(total_name)}).drop_duplicates(subset='id', keep='first').astype(str)
        assert name_df.duplicated().sum().sum() == 0
        return name_df, total_name, total_id


    name_df, total_name, total_id = assign_gene_names(tfs, rdb, grn_dir, total_name, total_id, noise_ids)

    # create anndata
    def to_anndata(counts:pd.DataFrame, celltypes: pd.DataFrame, coor:pd.DataFrame, name_df:pd.DataFrame):
        """

        :param counts: expression data. genes (row) x cells (col)
        :param celltypes: cell types
        :param coor: cell coordinates
        :param name_df: simulated ID - gene name
        :return: anndata.Anndata
        """
        df = counts.T
        adata = sc.AnnData(df)
        adata.obs['cells'] = list(df.index)
        adata.var['genes'] = list(df.columns)
        adata.obs['celltype'] = celltypes['cell.type']
        adata.obsm['spatial'] = coor.iloc[:int(df.shape[0])]
        data_genes = adata.var.copy()
        data_genes = data_genes['genes'].replace(list(name_df['id']), list(name_df['name']))
        data_genes = data_genes.to_frame()
        adata.var = data_genes
        adata.var_names = adata.var['genes']
        return adata

    adata = to_anndata(counts, celltypes, coor, name_df)
    adata.write_h5ad('lr.h5ad')

